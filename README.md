# ğŸ©¹ **Firstâ€‘Aid Chatbot**  
_Retrievalâ€‘Augmented Guidance from a Trusted Medical Manual_

---

## ğŸ§­Â Project Vision

Create an **interactive chatbot** that gives **fast, accurate, and contextâ€‘grounded firstâ€‘aid instructions** for any emergency scenario a user describes (burns, snakeâ€‘bites, fainting, etc.).  

The assistant should:

1. **Retrieve** facts _only_ from trusted medical sources.  
2. **Answer** with concise, stepâ€‘byâ€‘step guidance.  
3. **Cite** the page / section used.  
4. **Remember** the conversation to handle followâ€‘up questions.  
5. **Run fully offline** using local LLMs (Ollama).

---

## ğŸŒŸÂ Current FeaturesÂ (v0.2)

| Layer | Technology | Notes |
|-------|------------|-------|
| **LLM** | `llama3.2` via **Ollama** (local) | Streaming responses |
| **Embeddings** | `mxbaiâ€‘embedâ€‘large:335m` | Highâ€‘quality vectors |
| **VectorÂ Store** | **ChromaDB** (persisted) | Stores >5â€¯K chunks |
| **Document Source** | _IndianÂ First Aid ManualÂ (2016,Â 7thÂ ed.)_ | Loaded via `PyPDFLoader` |
| **Chunking** | `RecursiveCharacterTextSplitter` (1â€¯400â€¯chars, 10â€¯% overlap) | |
| **Retrievers** | `similarity` â€¢ `MMR` â€¢ _Multiâ€‘Query_ â€¢ _Contextual Compression_ | Empirically best: `MMR` (k=3, Î»=0.5) |
| **Prompt** | â€œAnswer ONLY from contextâ€¦ merge relevant infoâ€¦â€ | Hallucination guardrail |
| **LangChainÂ Pipeline** | `RunnableParallel` â†’ `PromptTemplate` â†’ `OllamaLLM` â†’ `StrOutputParser` | LCEL |
| **Frontend** | **Streamlit** chat UI | Typing cursor, session history |

---

## ğŸš§Â Known Limitations

1. **No conversational memory** â€“ bot forgets previous turns.  
2. **Coldâ€‘start latency** (~6â€¯s first token) â€“ need caching & model streaming.  
3. **Retrieval quality** is â€œokayâ€ but not perfect on edge cases.  
4. **Single data source** â€“ manual only; lacks WHO / RedÂ Cross updates.

---
